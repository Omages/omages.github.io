<!DOCTYPE html>
<html>
  
<head>
  <meta charset="utf-8">
  <meta name="description" content="An Object is Worth 64x64 Pixels: Generating 3D Object via Image Diffusion">
  <meta name="keywords" content="Geometry Images, 3D generation, Generative model">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Object Images 64x</title>
  <link rel="icon" href="icon.png">
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script> -->
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');



  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://omages.github.io">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>

        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://github.com/3dlg-hcvc/DuoduoCLIP">
              DuoDuoCLIP: Efficient 3D Understanding with Multi-View Images, 2024
            </a> 
            <a class="navbar-item" href="https://arxiv.org/abs/2403.13289">
              Survey: Text-to-3D Shape Generation, 2024 
            </a>
            <a class="navbar-item" href="http://raywzy.com/CAD/">
              CAD: Photorealistic 3D Generation via Adversarial Distillation, 2023
            </a>
            <a class="navbar-item" href="https://shapeformer.github.io">
              Shape generation and completion (ShapeFormer), 2022
            </a>
            <a class="navbar-item" href="https://vcc.tech/research/2019/RPMNet">
              Motion prediction (RPM-Net), 2019
            </a>
          </div>
        </div>
      </div>

    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h2 class="title is-2 publication-title">
              An Object is Worth 64x64 Pixels: <br>
              Generating 3D Object via Image Diffusion
            </h2>
              <div class="is-size-5 publication-authors">
                <span class="author-block">
                  <a href="http://yanxg.art">Xingguang Yan</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://hanhung.github.io/">Han-Hung Lee</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="http://raywzy.com/">Ziyu Wan</a><sup>2</sup>,
                </span>
                <span class="author-block">
                  <a href="https://angelxuanchang.github.io/">Angel X. Chang</a><sup>1,3</sup>,
                </span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block"><sup>1</sup>Simon Fraser University</span>
                <span class="author-block"><sup>2</sup>City University of Hong Kong</span>
                <span class="author-block"><sup>3</sup>Canada-CIFAR AI Chair, Amii</span>
                
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- PDF Link. -->
                  <!-- <span class="link-block">
                    <a href="./" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Paper</span>
                    </a>
                  </span> -->
                  <!-- <span class="link-block">
                    <a href="./" class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supp</span>
                    </a>
                  </span> -->
                  <span class="link-block">
                    <a href="https://arxiv.org/abs/2408.03178"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="ai ai-arxiv"></i>
                      </span>
                      <span>arXiv</span>
                    </a>
                  </span>
                  <!-- Video Link. -->
                  <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
                  <!-- Code Link. -->
                  <span class="link-block">
                    <a href="https://github.com/3dlg-hcvc/omages"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fab fa-github"></i>
                      </span>
                      <span>Code</span>
                    </a>
                  </span>
                  <!-- Dataset Link. -->
                  <!-- <span class="link-block">
                <a href="./"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a> -->
                </div>

              </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Video teaser -->
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video id="teaser" autoplay controls height="100%">
          <source src="static/videos/vid_teaser.mp4" type="video/mp4">
        </video>
        <h2 class="subtitle has-text-centered">
          We present <b>Object Images</b> (Omages): An homage to the classic <a href="https://hhoppe.com/proj/gim/">Geometry Images</a>.
        </h2>
      </div>
    </div>
  </section>


  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              We introduce a new approach for generating realistic 3D models with UV maps through a representation termed "Object Images." This approach encapsulates surface geometry, appearance, and patch structures within a 64x64 pixel image, effectively converting complex 3D shapes into a more manageable 2D format. By doing so, we address the challenges of both geometric and semantic irregularity inherent in polygonal meshes. This method allows us to use image generation models, such as Diffusion Transformers, directly for 3D shape generation. Evaluated on the ABO dataset, our generated shapes with patch structures achieve point cloud FID comparable to recent 3D generative models, while naturally supporting PBR material generation.
            </p>
          </div> 
        </div>
      </div>

      <!-- 3D model viewer. -->
      <!-- <div class="content has-text-justified">
        <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
        <table align="center" width="900px">
          <tbody>
            <tr>
              <td>
                <model-viewer src="./static/glbs/testchair.glb" camera-orbit="45deg 55deg 2.5m"
                  alt="A completed model" style="width: 100%; height: 200;" shadow-intensity="1" camera-controls=""
                  auto-rotate="" ar="" ar-status="not-presenting">
                </model-viewer>
              </td>
              <td>
                <model-viewer src="./static/glbs/testmirror.glb" camera-orbit="45deg 55deg 2.5m"
                  alt="A completed model" style="width: 100%; height: 200;" shadow-intensity="1" camera-controls=""
                  auto-rotate="" ar="" ar-status="not-presenting">
                </model-viewer>
              </td>
              <td>
                <model-viewer src="./static/glbs/testchair.glb" camera-orbit="45deg 55deg 2.5m"
                  alt="45deg 0deg 2.5m" style="width: 100%; height: 200;" shadow-intensity="1" camera-controls=""
                  auto-rotate="" ar="" ar-status="not-presenting">
                </model-viewer>
              </td>
              <td>
                <model-viewer src="./static/glbs/testchair.glb" camera-orbit="45deg 55deg 2.5m"
                  alt="A completed model" style="width: 100%; height: 200;" shadow-intensity="1" camera-controls=""
                  auto-rotate="" ar="" ar-status="not-presenting">
                </model-viewer>
              </td>
            </tr>

            <tr>
              <td>
                <model-viewer src="./static/glbs/testchair.glb" camera-orbit="110deg 25deg 2.5m"
                  alt="A completed model" style="width: 100%; height: 200;" shadow-intensity="1" camera-controls=""
                  auto-rotate="" ar="" ar-status="not-presenting">
                </model-viewer>
              </td>
              <td>
                <model-viewer src="./static/glbs/testchair.glb" camera-orbit="110deg 25deg 2.5m"
                  alt="A completed model" style="width: 100%; height: 200;" shadow-intensity="1" camera-controls=""
                  auto-rotate="" ar="" ar-status="not-presenting">
                </model-viewer>
              </td>
              <td>
                <model-viewer src="./static/glbs/testchair.glb" camera-orbit="110deg 25deg 2.5m"
                  alt="A completed model" style="width: 100%; height: 200;" shadow-intensity="1" camera-controls=""
                  auto-rotate="" ar="" ar-status="not-presenting">
                </model-viewer>
              </td>
              <td>
                <model-viewer src="./static/glbs/testchair.glb" camera-orbit="110deg 25deg 2.5m"
                  alt="A completed model" style="width: 100%; height: 200;" shadow-intensity="1" camera-controls=""
                  auto-rotate="" ar="" ar-status="not-presenting">
                </model-viewer>
              </td>
            </tr>
          </tbody>
        </table>
      </div> -->
      <br>
      <h2 class="title is-3">Motivation</h2>
      <div class="content has-text-justified">
        <p>
          Recently, 3D generative models have shown impressive results in synthesizing 3D objects. However, many of the current 3D generative models treat 3D shapes as a "statue" like objects. In contrary to the many high-quality human-made 3D assets which contains rich geometric and semantically meaningful patches, the statue-like objects are difficult to edit, animate and interact with. For example, the <a href="https://sketchfab.com/3d-models/headphone-with-stand-4ffedc9bffad4a549f6e0a46b0f92b05">headphone</a> shown below has intricate geometric parts that its "statue" version does not capture. Also, on the right example <a href="https://sketchfab.com/3d-models/book-pack-658cf47227a141e8abc607e455b1be7b">the pack of book</a> consists of multiple books standing closely to each other, which is very difficult to separate through current single-view reconstruction techniques. 
          </p>
          <p>
          The core challenge to generate 3D shapes with proper geometric connectivity and semantic part structures is the <b>irregularity</b> of these properties, since most recent techinques require regular, tensorial input. We find that these irregularities can be effectively handled through packing the geometry, patch structures and material into an image format, which we term as "Object Images" or "omages" (A kind of Multi-Chart Geometry Images). In this work, we explore to use image diffusion model to generate low-resolution omages to show this paradigm of 3D generation is possible. For more details, please refer to our paper.
        </p>
      </div>
      <div class="container is-max-desktop">
        <div class="hero-body"> 
          <img src="./static/images/fig_motivation.png" class="interpolation-image"
            alt="Interpolation end reference image." />
        </div>
      </div>

      <h2 class="title is-3">Method</h2>
      <div class="content has-text-justified">
        <p>
          We first preprocess the UV-unwrapped 3D shapes into 1024x1024 omages and then downsample it with special care to 64x64 omages. Then we just flatten the omage into a sequence and learn their distribution through a Diffusion Transformer (DiT) of patch size 1. The motivation of using DiT is that we observe the generation of omages is essentially image generation and set generation combined. A very cool thing is that during the denoising process, discrete structures emerge out of the continuous image format, and the generated results exhibit great variety in the number and size of patches.
        </p>
      </div>
      <div class="container is-max-desktop">
        <div class="hero-body">
          <img src="./static/images/fig_pipeline.png" class="interpolation-image"
            alt="Interpolation end reference image." />
          <!-- line break -->
          <br>
          <img src="./static/images/fig_teaser.png" class="interpolation-image"
            alt="Interpolation end reference image." />
        </div>
      </div>


      <h2 class="title is-3">More results samples</h2>
      <div class="content has-text-justified">
        <p>
          Here we show some more results of our model trained on the ABO dataset. Although there are gaps between the patches, the overall alignment of the patches demonstrate the potential of this 3D generation paradigm. We also show the potential of our model to generate objects with PBR materials, like mirrors.
        </p>
      </div>
      <div class="container is-max-desktop">
        <div class="hero-body">
          <img src="./static/images/fig_gallery.png" class="interpolation-image"
            alt="Interpolation end reference image." />
        </div>
      </div>

      <!-- <h2 class="title is-3">What's next?</h2>
      <div class="content has-text-justified">
        <p>
          In the 
          We advocate that the omages can be quite handy for 3D shapes, and we are excited to see the potential of this representation in various applications. We are also interested in exploring the potential of omages in other tasks, such as 3D reconstruction, 3D editing, and 3D animation. We hope this work can inspire more research in this direction.
        </p>
      </div> -->



  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@misc{yan2024omages64,
  title={An Object is Worth 64x64 Pixels: Generating 3D Object via Image Diffusion}, 
  author={Xingguang Yan and Han-Hung Lee and Ziyu Wan and Angel X. Chang},
  year={2024},
  eprint={2408.03178},
  archivePrefix={arXiv},
  url={https://arxiv.org/abs/2408.03178}, 
}
</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link" href="static/ShapeFormer.pdf">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/qheldiv/shapeformer" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              We create this website based on the source code of <a
                href="https://github.com/nerfies/nerfies.github.io">nerfies.github.io</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>
